{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sim2', 'av2017']\n",
      "dict_keys(['univariate_categorical', 'univariate_dates', 'bivariate_categorical', 'categorical_cross_diagnosis_date', 'categorical_cross_surgery_date', 'surgery_date_cross_diagnosis_date'])\n"
     ]
    }
   ],
   "source": [
    "# Third-party imports\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import getpass\n",
    "import cx_Oracle\n",
    "\n",
    "# Local packages\n",
    "from database import connect\n",
    "from populations import pop_queries\n",
    "# import queries\n",
    "import analysis\n",
    "import compute_stats\n",
    "import plots\n",
    "from params import key_list, comparison_pairs, filepath_dictionary, field_list_dict\n",
    "\n",
    "print(key_list)\n",
    "print(field_list_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to an SQL database with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Oracle Instant Client - Installation instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interacting with an Oracle RDBMS requires Oracle Client libraries to be installed. You can read more about this [here](https://oracle.github.io/odpi/doc/installation.html). \n",
    "\n",
    "In general, Oracle Client libraries come with your Oracle Database installation or full Oracle Client installation. To connect to an Oracle RDBMS using Python, you need to install Oracle Instant Client. We will describe only one of the many possible ways to install Oracle Instant Client in a way that allows you to access an Oracle Database using Python from your local machine. Please follow the installation instructions below:\n",
    "\n",
    "1. **Download the Oracle Instant Client zip files.** You can find the appropriate installer for your machine [here](https://oracle.github.io/odpi/doc/installation.html). For example, for Windows 64-bit machines you will be directed to download the Oracle Instant Client Basic Package from [this webpage](https://www.oracle.com/database/technologies/instant-client/winx64-64-downloads.html).\n",
    "2. **Install the libraries where Python can read them.** Copy the contents of the `instantclient_19_3` folder (found inside the zipped folder you have just downloaded) to `C:\\Users\\<username>\\AppData\\Local\\Continuum\\miniconda3\\envs\\<my_conda_environment>\\DLLs`\n",
    "\n",
    "Step 2 assumes you used [Miniconda3](https://docs.conda.io/en/latest/miniconda.html) to install the `conda` package manager (and Python 3), and that you set up a custom environment for your project rather than using the base environment (highly recommended), but this should be generalizable. In particular, copying the contents of `instantclient_19_3` to the folder `C:\\Users\\<username>\\AppData\\Local\\Continuum\\miniconda3\\DLLs` would install the Oracle Instant Client libraries into your base environment.\n",
    "\n",
    "These instructions are somewhat Windows-centric, and in fact, if you have Python running already, you could install the files into any folder on your `PYTHONPATH`, which you can find out about by running `import sys; print(sys.path)` in Python. The specific folder location in this tutorial was chosen since it is a natural place to install [.dll files](https://whatis.techtarget.com/fileformat/DLL-Dynamic-link-library-file) such as those which comprise the Oracle Instant Client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username:analysispaulclarke\n",
      "password:········\n"
     ]
    }
   ],
   "source": [
    "db = connect(input('username:'), getpass.getpass('password:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the data from sim2 - calculating categorical_cross_surgery_date counts in SQL...\n",
      "Totals pulled from database successfully! (922704 rows, 5 columns)\n",
      "Setting data types and cleaning values...\n",
      "Sorting values...\n",
      "Data cleaned and sorted!\n",
      " Saving the results...\n",
      "Saved successfully at E:\\SIM2_categorical_cross_surgery_dates.csv ! Function complete!\n",
      "Getting the data from av2017 - calculating categorical_cross_surgery_date counts in SQL...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(cx_Oracle.OperationalError) ORA-03113: end-of-file on communication channel\nProcess ID: 78410\nSession ID: 354 Serial number: 33601\n(Background on this error at: http://sqlalche.me/e/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\result.py\u001b[0m in \u001b[0;36mfetchall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetchall_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soft_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\result.py\u001b[0m in \u001b[0;36m_fetchall_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: ORA-03113: end-of-file on communication channel\nProcess ID: 78410\nSession ID: 354 Serial number: 33601",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-17d2708ea410>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'categorical_cross_surgery_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surgery_date_cross_diagnosis_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m              \u001b[0mwrite_counts_to_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\SimulacrumSVN\\trunk\\Test suite EP\\write_results.py\u001b[0m in \u001b[0;36mwrite_counts_to_csv\u001b[1;34m(count_type, key, db)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# Read the raw table of counts data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting the data from {} - calculating {} counts in SQL...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_totals_from_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Totals pulled from database successfully! ({} rows, {} columns)'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\SimulacrumSVN\\trunk\\Test suite EP\\write_results.py\u001b[0m in \u001b[0;36mget_totals_from_db\u001b[1;34m(count_type, key, db)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcount_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'bivariate_categorical'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'categorical_cross_diagnosis_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'categorical_cross_surgery_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surgery_date_cross_diagnosis_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mnum_variates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_totals_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_queries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfield_list_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_variates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_variates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[0;32m   1229\u001b[0m             )\n\u001b[0;32m   1230\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m             frame = _wrap_result(\n\u001b[0;32m   1233\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\result.py\u001b[0m in \u001b[0;36mfetchall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             self.connection._handle_dbapi_exception(\n\u001b[1;32m-> 1216\u001b[1;33m                 \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m             )\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1474\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_from_cause\u001b[1;34m(exception, exc_info)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0mcause\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb, cause)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcause\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\result.py\u001b[0m in \u001b[0;36mfetchall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1211\u001b[1;33m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetchall_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soft_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\testing_environment\\lib\\site-packages\\sqlalchemy\\engine\\result.py\u001b[0m in \u001b[0;36m_fetchall_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fetchall_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_non_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (cx_Oracle.OperationalError) ORA-03113: end-of-file on communication channel\nProcess ID: 78410\nSession ID: 354 Serial number: 33601\n(Background on this error at: http://sqlalche.me/e/e3q8)"
     ]
    }
   ],
   "source": [
    "from write_results import write_counts_to_csv\n",
    "\n",
    "for count_type in field_list_dict.keys():\n",
    "    if count_type in ['categorical_cross_surgery_date', 'surgery_date_cross_diagnosis_date']:\n",
    "        for key in key_list:\n",
    "             write_counts_to_csv(count_type, key, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to read the tables of counts data from local files and combine pairs of tables which we want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_types = ['univariate_categorical', 'univariate_dates', 'bivariate_categorical', \n",
    "               'categorical_cross_diagnosis_date', 'categorical_cross_surgery_date', 'surgery_date_cross_diagnosis_date']\n",
    "combined_counts = {count_type: analysis.combine_counts(count_type, analysis.read_counts(count_type)) \n",
    "                   for count_type in count_types}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Basic metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Having successfully read the counts data above, and joined the counts data from tables we wish to compare, we can check the sizes of the resulting tables and that the sum of category sizes within each field is equal to the number of rows in the corresponding source data table as we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim2 vs. av2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>univariate_categorical</th>\n",
       "      <td>(2844, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>univariate_dates</th>\n",
       "      <td>(10748, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bivariate_categorical</th>\n",
       "      <td>(776539, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_cross_diagnosis_date</th>\n",
       "      <td>(1182778, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_cross_surgery_date</th>\n",
       "      <td>(1155398, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surgery_date_cross_diagnosis_date</th>\n",
       "      <td>(142662, 4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sim2 vs. av2017\n",
       "univariate_categorical                  (2844, 4)\n",
       "univariate_dates                       (10748, 4)\n",
       "bivariate_categorical                 (776539, 6)\n",
       "categorical_cross_diagnosis_date     (1182778, 5)\n",
       "categorical_cross_surgery_date       (1155398, 5)\n",
       "surgery_date_cross_diagnosis_date     (142662, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_table_sizes = pd.DataFrame({count_type: {pair[0]+' vs. '+pair[1]: frame.shape for pair, frame in comparison_tables.items()} for count_type, comparison_tables in combined_counts.items()}).T\n",
    "joined_table_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data entries in the sim2 cohort is 2371686: False\n",
      "The number of data entries in the av2017 cohort is 2483089: False\n"
     ]
    }
   ],
   "source": [
    "from compute_stats import pop_sizes\n",
    "\n",
    "def check_pop_sizes():\n",
    "    for pair, comparison_table in combined_counts['univariate_categorical'].items():\n",
    "        totals_by_category = comparison_table.groupby(by='column_name').sum()\n",
    "        for key in pair:\n",
    "            check = (totals_by_category['counts_'+key] == pop_sizes[key]).all()\n",
    "            print('The number of data entries in the {} cohort is {}: {}'.format(key, pop_sizes[key], check))\n",
    "\n",
    "check_pop_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preliminary checks on counts data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some cases of particular interest may include:\n",
    "- Simulated values which are not present in the real dataset (although we typically wouldn't worry about this in the case of datetime fields). Such values could not have been sampled from the real data, and statistical tests cannot be meaningfully carried out on these values since they are not expected to occur at all based on the real data.\n",
    "- Real values which are not present in the simulated dataset. Sometimes this can be explained as reasonable if the values are themselves rare in the real data, however this can also help to identify values which are being significantly underrepresented in the simulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using Python's Pandas package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def join_comparison_tables(count_type, combined_counts):\n",
    "    # Repeat the process of joining tables and filling in the missing zeros\n",
    "    all_joined = pd.merge(combined_counts[count_type][comparison_pairs[0]], combined_counts[count_type][comparison_pairs[1]], \n",
    "                          on=analysis.join_cols[count_type], how='outer')\n",
    "    count_cols = ['counts_'+key for key in key_list]\n",
    "    all_joined[count_cols] = all_joined[count_cols].fillna(0, axis=1).astype('uint32')\n",
    "    return all_joined\n",
    "\n",
    "def check_zeros(table, ignore=['DATE_FIRST_SURGERY', 'DIAGNOSISDATEBEST']):\n",
    "    check = (table == 0).any(axis=1)\n",
    "    for field in ignore:\n",
    "        check = check & (table.column_name != field)\n",
    "    return table.loc[check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df4626a8ede4160acbfd8b182bad1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col_name', options=('QUINTILE_2015', 'CREG_CODE', 'GRADE', 'SEX', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(col_name)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda col_name: check_zeros(join_comparison_tables('univariate_categorical', combined_counts)).query(\"column_name == '{}'\".format(col_name)), col_name=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Joining directly in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb = pd.read_sql_query(queries.all_counts_query(pop_queries['sim1'], pop_queries['av2015']), db)\n",
    "print(totals_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb2 = pd.read_sql_query(queries.all_counts_query(pop_queries['sim2'], pop_queries['av2017']), db)\n",
    "print(totals_comb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.query(\"counts_r == 0\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.query(\"(counts_s == 0) and (counts_r >= 10)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def view_by_column_name_widget(table, options):\n",
    "    return interact(lambda col_name: table.query(\"col_name == '{}'\".format(col_name)), col_name=options);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_by_column_name_widget(totals_comb, field_list_dict['univariate_categorical']+field_list_dict['univariate_dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Statistical Tests (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If the cells containing LaTeX code don't render nicely in your Jupyter Notebook (especially after opening a collapsed header), then simply rerun the Markdown cell to redraw the cell correctly. You can do this by selecting the cell in Command Mode (indicated by a grey cell border with a blue left margin, press `Esc` to enable) using the up/down arrow keys, then hit `Enter`, followed by `Ctrl-Enter`.\n",
    "\n",
    "See the documentation in `compute_stats.py` for further information on the computation of statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Binomial test: Approximation by z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### One-sample z-test with binomial assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We test the null hypothesis \n",
    "\n",
    "$$H_0: X_{C}\\sim\\mathrm{Bin}(n,\\hat{p}_{C})$$ \n",
    "\n",
    "that the occurrence $X_{C}$ of category $C$ in the simulated tumour dataset was sampled from a binomial distribution $\\mathrm{Bin}(n,\\hat{p}_{C})$ where $n$ is the number of simulated tumour entries/rows and $\\hat{p}_{C}$ is the proportion of real tumour entries which fall into category $C$, against the alternative hypothesis that the simulated dataset was sampled in some other way (e.g. $X$ binomially distributed with a different value of $p$; $X$ not binomially distributed because $p$ not constant between trials or trials not independent, etc). \n",
    "\n",
    "If n is large enough, then the skew of the Binomial distribution is not too great. In this case a reasonable approximation to $B(n, p)$ is given by the normal distribution $\\mathcal{N}(np,np(1-p))$. - [Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation)\n",
    "\n",
    "In this case we may use the test statistic \n",
    "\n",
    "$$z = \\frac{X - np}{\\sqrt{np(1-p)}}\\sim\\mathcal{N}(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### When is the normal approximation appropriate?\n",
    "\n",
    "We apply the rule which states that the normal approximation is appropriate only if everything within 3 standard deviations of its mean is within the range of possible values; that is, only if\n",
    "\n",
    "$$\\mu \\pm 3\\sigma =np\\pm 3{\\sqrt {np(1-p)}}\\in (0,n)$$\n",
    "\n",
    "This 3-standard-deviation rule is equivalent to the following conditions:\n",
    "\n",
    "$$n>9\\left({\\frac {1-p}{p}}\\right)\\quad {\\text{and}}\\quad n>9\\left({\\frac {p}{1-p}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below draws a graph to illustrate how the continous normal distribution approximates the discrete binomial distribution. The vertical lines show the probability mass functions of different binomial distributions whilst the smooth black lines show the probability distribution functions of their corresponding approximating normal distributions, which are based on the mean and variances of their respective binomial distibution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, norm\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "\n",
    "n = 40\n",
    "colors = ['b', 'y', 'r']\n",
    "probs = [0.7, 0.9, 0.99]\n",
    "binom_dists = [binom(n, p) for p in probs]\n",
    "moments = [drv.stats(moments='mv') for drv in binom_dists]\n",
    "norm_dists = [norm(loc=mv[0], scale=np.sqrt(mv[1])) for mv in moments]\n",
    "\n",
    "x = np.arange(20, 41)\n",
    "#x = [np.arange(drv.ppf(0.005), drv.ppf(0.995)) for drv in binom_dists]\n",
    "x1 = [np.linspace(crv.ppf(0.005), crv.ppf(0.995), 100) for crv in norm_dists]\n",
    "\n",
    "for i in range(len(probs)):\n",
    "    ax.vlines(x, 0, binom_dists[i].pmf(x), color=colors[i], label='p = {} and n = {}'.format(probs[i], n))\n",
    "    ax.plot(x1[i], norm_dists[i].pdf(x1[i]), 'k')\n",
    "ax.set_xlabel('$x$', fontsize = 24) \n",
    "ax.set_ylabel('$P(X=x)$', fontsize = 24) \n",
    "ax.set_title('Binomial distributions and their Normal approximations', fontsize = 24) \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice that the as the success probability $p$ gets closer to $0$ or $1$, the binomial distribution gets more skewed/less symmetric, and matches up less well with its normal approximation (which is always symmetric about its mean value). In these extreme cases, the normal approximation also assigns nontrivial probabilities to impossible events under the binomial setup (i.e. more success than trials, or negative number of successes). \n",
    "\n",
    "For these reasons, using the z-test statistic in these cases may lead to misleading results, namely an increased number of Type I errors - rejecting a true null hypothesis, which in our case means identifying more simulated categories as failing to closely match their real counterparts than is truely the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We may wish to check the feasibility of calculating the exact binomial test statistics using SciPy in some cases.\n",
    "\n",
    "Sample code:\n",
    "`scipy.stats.binom_test(51, 235, 1.0/6, alternative='two-sided')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pooled two-sample z-test with binomial assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assuming first that the occurrence of category $C$ in the real and simulated datasets are each binomially distributed (with number of trials equal to the number of data entries/rows), the pooled two-sample z-test tests the null hypothesis that these binomial distribitions both have the same underlying success probability parameter $p$. \n",
    "\n",
    "We are modelling the number of occurrences $X_{1}, X_{2}$ of category $C$ in the simulated (resp. real) datasets by $X_{i}\\sim\\mathrm{Bin}(n_{i},p_{i})$, where $n_{1}$ ($n_{2}$) is the number of rows in the simulated (real) dataset, $p_{1}$ ($p_{2}$) is the probability of a data row falling into category $C$ when the simulated (resp. real) dataset was sampled/obtained, respectively.\n",
    "\n",
    "The null hypothesis is $$H_0: p_{1} = p_{2} = p$$ \n",
    "\n",
    "We estimate the probabilities $p_{1}, p_{2}$ by the proportions $\\hat{p}_{i} = X_{i}/n_{i}$ of occurences of category $C$ in the simulated (real) dataset, respectively. If the null hypothesis is true, our best estimate for $p$ is $$\\hat{p} = \\frac{X_{1} + X_{2}}{n_{1} + n_{2}}$$\n",
    "\n",
    "We have the following test statistic:\n",
    "\n",
    "$$z = \\frac{\\hat{p}_{1} - \\hat{p}_{2}}{\\sqrt{\\hat{p}(1 - \\hat{p})(\\frac{1}{n_{1}} + \\frac{1}{n_{2}})}}\\sim\\mathcal{N}(0,1)$$\n",
    "\n",
    "This test has the advantage of still being calculable in the case that $\\hat{p}_{2}=0, \\hat{p}_{1}\\ne0$ due to zero occurences of a particular value/category in the real data, which might reasonably occur in the case of date fields and some fields relating to rare cancers. The previous one-sample z-test would produce an infinite test statistic when $X\\ne0$ due to dividing by zero, which indicates an expected number of entries in the given category being exactly 0 with absolute certainty.\n",
    "\n",
    "For more details, see the explanation [here](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Two_Proportions.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pearson's chi-squared test and Likelihood-ratio/G-test for each field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can read the Wikipedia pages for background on the various kinds of [multinomial test](https://en.wikipedia.org/wiki/Multinomial_test), namely:\n",
    "- [Pearson's chi-squared test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
    "![Pearson's chi-squared test](https://wikimedia.org/api/rest_v1/media/math/render/svg/c4fd8945d1bdd2aa3cc133571cb8bb0b232fac3b)\n",
    "- [Likelihood-ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test) (a.k.a. [G-test](https://en.wikipedia.org/wiki/G-test))\n",
    "![G-test](https://wikimedia.org/api/rest_v1/media/math/render/svg/fefb45c7ddf75da6452e9bfdcb17925d1b690552)\n",
    "\n",
    "It is necessary to calculate the test statistics based on proportions since the size of the real and simulated datasets are not equal. We use number of degrees of freedom equal to number of categories minus 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Normalizing the test statistics for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We would like to be able to compare chi-squared test results when the number of degrees of freedom (i.e. the number of categories minus one) varies for different fields. To do this we normalize the test statistics in two different ways:\n",
    "\n",
    "> By the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem), because the chi-square distribution is the sum of $k$ independent random variables with finite mean and variance, it converges to a normal distribution for large $k$. Specifically, if $X\\sim\\chi^{2}(k)$, then as $k$ tends to infinity, the distribution of $(X-k)/\\sqrt{2k}$ tends to a standard normal distribution. - [Wikipedia](https://en.wikipedia.org/wiki/Chi-squared_distribution#Asymptotic_properties)\n",
    "\n",
    "Therefore we first compute a `normalized_score` based on the chi-squared test statistic $X$ with $k$ degrees of freedom as \n",
    "\n",
    "$$z = \\frac{X-k}{\\sqrt{2k}}\\sim\\mathcal{N}(0,1)$$\n",
    "\n",
    "which better resembles a standard normal distribution the greater the value of $k$.\n",
    "\n",
    "It is known that the convergence of this first normalized score to the standard normal distribution is slow due to high skew and excess kurtosis, and so we also derive an alternative normalized score from each chi-squared test statistic called the `Wilson-Hilferty_score`, which converges to normality much faster under the null hypothesis.\n",
    "\n",
    "We will apply a [Wilson–Hilferty transformation](https://en.wikipedia.org/wiki/Chi-squared_distribution#Asymptotic_properties) to the Pearson's chi-squared test statistics which approximately normalizes them (under the null hypothesis).\n",
    "\n",
    "That is, if $X\\sim\\chi^{2}(k)$ then $\\sqrt[3]{X/k}$ is approximately normally distributed with mean $1-2/(9k)$ and variance $2/(9k)$, where $k$ is the number of degrees of freedom.\n",
    "\n",
    "Therefore, for each Pearson's chi-squared test statistic $X$, we apply the transformation to obtain\n",
    "\n",
    "$$z = \\frac{\\sqrt[3]{X/k} - (1-2/(9k))}{2/(9k)} = \\frac{9}{2}\\sqrt[3]{k^{2}X} - \\frac{9k}{2} + 1\\sim\\mathcal{N}(0,1)$$\n",
    "\n",
    "which will follow the standard normal distribution under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Kolmogorov-Smirnov test for continuous-like fields (dates, ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can read the Wikipedia page for an explanation of the two-sample [Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test). \n",
    "\n",
    "The test statistic is the maximum vertical distance between empirical cumulative distribution functions (CDFs), as illustrated below: ![Kolmogorov-Smirnov test example](https://upload.wikimedia.org/wikipedia/commons/3/3f/KS2_Example.png)\n",
    "_Illustration of the two-sample Kolmogorov–Smirnov statistic. Red and blue lines each correspond to an empirical distribution function, and the black arrow is the two-sample KS statistic._ - [Wikipedia](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing test statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_z_test_results = {pair: compute_stats.compute_z_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_categorical'].items()}\n",
    "bivariate_z_test_results = {pair: compute_stats.compute_z_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['bivariate_categorical'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_chi2_test_results = {pair: compute_stats.compute_chi2_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_categorical'].items()}\n",
    "bivariate_chi2_test_results = {pair: compute_stats.compute_chi2_test(pair, comparison_table, grouping='bivariate') \n",
    "                             for pair, comparison_table in combined_counts['bivariate_categorical'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_dates'].items()}\n",
    "diagnosis_date_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table, grouping='bivariate')\n",
    "                                  for pair, comparison_table in combined_counts['categorical_cross_diagnosis_date'].items()}\n",
    "surgery_date_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table, grouping='bivariate')\n",
    "                                  for pair, comparison_table in combined_counts['categorical_cross_surgery_date'].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SQL implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will add the following columns to our table to further analyse and compare the real and simulated datasets:\n",
    "- The fraction/proportion of all entries in the corresponding table which take on a given value\n",
    "- A normal approximation to a one-sample binomial test statistic, and a flag for whether the normal approximation is appropriate\n",
    "- Pooled two-sample z-test statistics based on binomial assumptions\n",
    "- Summands for computing Pearson's chi-squared and Likelihood-ratio test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df = pd.read_sql_query(queries.compute_stats_query(pop_queries['sim1'], pop_queries['av2015']), db)\n",
    "print(analysis_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_by_column_name_widget(analysis_df, field_list_dict['univariate_categorical']+field_list_dict['univariate_dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results: Pandas implementation + Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot bar charts of z-test results for univariate categorical comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below produces an interactive widget which allows you to select the column name of a categorical field and produces a grouped bar chart where the bar heights (y-axis) represent z-test statistic values, and the categories/values in the chosen field run along the x-axis. \n",
    "\n",
    "A positive bar height indicates over-representation of a given category, and negative bar height indicates under-representation of the given category in the simulated data relative to the training data. Bars with absolute height greater than 2 are highlighted with a red border to indicate relatively larger divergences between the simulated data and the real data.\n",
    "\n",
    "The bar charts are grouped into two groups: the first for z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacrum) Version 1 (publicly released and [available online](https://simulacrum.healthdatainsight.org.uk/)) against its corresponding training cohort in AV2015 (2013-2015 finalised tumour records in England), and the second group of bar charts indicate z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacra_and_Simulation) Version 2 against its corresponding training cohort in AV2017 (2013-2017 finalised tumour records in England)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce5eb724fe4cc98c1d38c326556cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col_name', options=('QUINTILE_2015', 'CREG_CODE', 'GRADE', 'SEX', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(col_name)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda col_name: plots.plot_univariate_categorical_results(univariate_z_test_results, col_name), col_name=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot heatmaps of z-test results for bivariate categorical comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below produces an interactive widget which allows you to select a pair of categorical fields and produces heatmaps where the colour (z-axis) indicates z-test statistic values, and the categories being compared are indicated by (x,y)-pairs of values in the chosen fields. The x-axis and y-axis can be swapped by reversing the order of the selected field pair.\n",
    "\n",
    "A deeper shade of red indicates over-representation of a given category, and a deeper shade of blue indicates under-representation of the given category in the simulated data relative to the training data. Broadly speaking, deeper colours indicate relatively larger divergences between the simulated data and the real data, whilst lighter shades indicate a small divergence between real and simulated data in proportional size of a given category. A colorscale is provided, and hovering over the coloured rectangles with the cursor will reveal the exact z-test statistic values.\n",
    "\n",
    "In the case of structural zeros, where there are zero counts for a given category in both the real and simulated data, a z-test statistic is not computed and no colour value is shown (grey background with gridlines). This indicates good performance in the simulated data at recognizing uncommon/impossible category combinations in the real data. For example, according to the [NHS](https://www.nhs.uk/conditions/prostate-cancer/causes/) most cases of prostate cancer are diagnosed in men over 50 years of age, and this is reflected in the heatmap plots for Gleason grade scores (for prostate cancers) against age or gender.\n",
    "\n",
    "Two heatmaps are produced: the first for z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacrum) Version 1 (publicly released and [available online](https://simulacrum.healthdatainsight.org.uk/)) against its corresponding training cohort in AV2015 (2013-2015 finalised tumour records in England), and the second indicates z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacra_and_Simulation) Version 2 against its corresponding training cohort in AV2017 (2013-2017 finalised tumour records in England)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7e69f7bb6c4093964f03906a0e1ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col_name1', options=('QUINTILE_2015', 'CREG_CODE', 'GRADE', 'SEX',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(col_name1, col_name2)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda col_name1, col_name2: plots.plot_bivariate_categorical_results(bivariate_z_test_results, col_name1, col_name2) \n",
    "         if col_name1 != col_name2 else plots.plot_univariate_categorical_results(univariate_z_test_results, col_name1),\n",
    "         col_name1=field_list_dict['univariate_categorical'], col_name2=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot chi-squared test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Performance over single fields (univariate chi-squared test results) - Bar charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below produces an interactive horizontal grouped bar chart where names of data fields derived from AV_TUMOUR tables run along the y-axis, and the bar lengths (x-axis) represent the corresponding Pearson's chi-squared test statistics, or some transformation of them chosen by the user to normalize them. Please see [section 3.2](#Pearson's-chi-squared-test-and-Likelihood-ratio/G-test-for-each-field) for more information on how the test statistics are calculated. \n",
    "\n",
    "Hovering over an individual bar will reveal the Pearson's chi-squared test statistic value, the number of degrees of freedom (i.e. the number of categories/field values minus 1), the normalized score, and the Wilson-Hilferty score; one of which is plotted as the bar length. It is also possible to zoom in and pan to different areas of the figure.\n",
    "\n",
    "Under the null hypothesis, the Pearson's chi-squared test statistics will each follow a chi-squared distribution with the respective number of degrees of freedom, and the normalized score and the Wilson–Hilferty transformation of the statistic will be distributed as Normal(0,1). \n",
    "\n",
    "Therefore, based on the formulation of the test statistic and the normalized scores, absolute bar length corresponds to the magnitude of difference between the real dataset and the simulated dataset in terms of distribution of values for a given field, with a large absolute bar lengths indicating a significant divergence in distribution between the real dataset and the simulated dataset, and small absolute bar lengths (close to zero) indicating fields for which the distribution of values in the real and simulated datasets are closely matched. The bar lengths are shown on a logarithmic scale.\n",
    "\n",
    "The bar charts are in two groups: the first for the normalized chi-squared test scores from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacrum) Version 1 (publicly released and [available online](https://simulacrum.healthdatainsight.org.uk/)) against its corresponding training cohort in AV2015 (2013-2015 finalised tumour records in England), and the second group of bar charts indicate normalized chi-squared test scores from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacra_and_Simulation) Version 2 against its corresponding training cohort in AV2017 (2013-2017 finalised tumour records in England)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda by: plots.plot_univariate_chi2_test_results(univariate_chi2_test_results, by), by=['pearson_chi2_test', 'normalized_score', 'Wilson–Hilferty_score', 'degrees_of_freedom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance over pairs of fields (bivariate chi-squared test results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below produces an interactive heatmap where the colour (z-axis) indicates the value of the Pearson's chi-squared test statistic (or a normalization of it) corresponding to a given (x,y)-pair of data fields derived from AV_TUMOUR tables. Please see [section 3.2](#Pearson's-chi-squared-test-and-Likelihood-ratio/G-test-for-each-field) for more information on how the test statistics are calculated. \n",
    "\n",
    "Hovering over an individual coloured rectangle will reveal the Pearson's chi-squared test statistic value, the number of degrees of freedom (i.e. the number of categories/field values minus 1), the normalized score, and the Wilson-Hilferty score; one of which is plotted as the bar length. It is also possible to zoom in and pan to different areas of the figure. Note that the heatmap is symmetric about the diagonal.\n",
    "\n",
    "Under the null hypothesis, the Pearson's chi-squared test statistics will each follow a chi-squared distribution with the respective number of degrees of freedom, and the normalized score and the Wilson–Hilferty transformation of the statistic will be distributed as Normal(0,1). \n",
    "\n",
    "Therefore, based on the formulation of the test statistic and the normalized scores, the colour corresponds to the magnitude of difference between the real dataset and the simulated dataset in terms of distribution of values for a given field, with a (certain type of) colour indicating a significant divergence in distribution between the real dataset and the simulated dataset, and (different kind of) colour (representing scores close to zero) indicating fields for which the distribution of values in the real and simulated datasets are closely matched. A logarithmic colorscale is also provided.\n",
    "\n",
    "Two heatmaps are produced: the first for z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacrum) Version 1 (publicly released and [available online](https://simulacrum.healthdatainsight.org.uk/)) against its corresponding training cohort in AV2015 (2013-2015 finalised tumour records in England), and the second indicates z-test statistic values from comparing [Simulacrum](https://en.wikipedia.org/wiki/Simulacra_and_Simulation) Version 2 against its corresponding training cohort in AV2017 (2013-2017 finalised tumour records in England)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf32b29b11548398a631f22e876bca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='by', options=('pearson_chi2_test', 'normalized_score', 'Wilson–Hil…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(by)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda by: plots.plot_bivariate_chi2_results(bivariate_chi2_test_results, by), by=['pearson_chi2_test', 'normalized_score', 'Wilson–Hilferty_score', 'degrees_of_freedom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Kolmogorov-Smirnov test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair, frame in univariate_ks_test_results.items():\n",
    "    print(pair, '\\n', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDFs should be scaled to run from 0 to 1 so that KS-tests are comparable between large and small categories in the bivariate case, and to account for the existence of null values in the univariate case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose date field, comparison pair, and field (column_name1) to view table\n",
    "\n",
    "# for pair, frame in diagnosis_date_ks_test_results.items():\n",
    "#     print(pair, '\\n', frame)\n",
    "\n",
    "# for pair, frame in surgery_date_ks_test_results.items():\n",
    "#     print(pair, '\\n', frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting cumulative distribution functions (CDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDFs should be scaled to run from 0 to 1 so that KS-tests are comparable between large and small categories in the bivariate case, and to account for the existence of null values in the univariate case.\n",
    "\n",
    "Stacked [area plots](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#area-plot) could also be used for visualization in the bivariate case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pair = ('sim1', 'av2015')\n",
    "compute_stats.compute_cdf(pair, combined_counts['univariate_dates'][pair]).query(\"column_name == 'DATE_FIRST_SURGERY'\").plot('val', ['cdf_'+key for key in pair],\n",
    "                                                                                                              xlim=('2013', '2016'))\n",
    "# compute_cdf(pair, combined_counts['univariate_categorical'][pair].query(\"column_name == 'AGE'\")).plot('val', ['cdf_'+key for key in pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "x_vals = cumsum_results['val_clean']\n",
    "for key in key_list:\n",
    "    y_vals = cumsum_results['proportion_'+key]\n",
    "    fig.add_trace(go.Scatter(x=x_vals, y=y_vals, name=\"CDF: \"+key))\n",
    "\n",
    "fig.update_layout(title_text='Time Series with Rangeslider',\n",
    "                  xaxis_rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Diagnosis Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Date of First Surgery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Assessing the distribution of the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df.iloc[:,2:].abs().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df[['binom_z_test_one_sample', 'z_test_two_sample_pooled']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df[['binom_z_test_one_sample', 'z_test_two_sample_pooled']].plot.box(vert=False, figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "for ax in axes:\n",
    "    ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df[['binom_z_test_one_sample']].hist(bins=2500, density=True, ax=axes[0])\n",
    "analysis_df[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=axes[1])\n",
    "# Set the limits for the x-axis\n",
    "axes[0].set_xlim(-7,7);\n",
    "axes[0].set_title('Histogram of one-sample z-test statistics over all categories in all fields', fontsize = 24);\n",
    "axes[1].set_xlim(-7,7);\n",
    "axes[1].set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "for ax in axes:\n",
    "    ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df2[['binom_z_test_one_sample']].hist(bins=2500, density=True, ax=axes[0])\n",
    "analysis_df2[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=axes[1])\n",
    "# Set the limits for the x-axis\n",
    "axes[0].set_xlim(-7,7);\n",
    "axes[0].set_title('Histogram of one-sample z-test statistics over all categories in all fields', fontsize = 24);\n",
    "axes[1].set_xlim(-7,7);\n",
    "axes[1].set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=ax)\n",
    "# Set the limits for the x-axis\n",
    "ax.set_xlim(-7,7)\n",
    "ax.set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exporting matplotlib plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# variables = ['PERFORMANCESTATUS', 'CNS', 'ACE27', 'N_BEST']\n",
    "# for variable in variables:\n",
    "#     plots.plot_by_category(analysis_df, variable, 'Pooled Two-sample Binomial z-test')\n",
    "#     plt.savefig(\"z_test_plot_{}.png\".format(variable), transparent=False, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "386.969px",
    "left": "1341.99px",
    "right": "20px",
    "top": "119.989px",
    "width": "558.969px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
